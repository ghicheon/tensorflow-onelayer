{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">TensorFlow Neural Network Lab</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/notmnist.png\">\n",
    "In this lab, you'll use all the tools you learned from *Introduction to TensorFlow* to label images of English letters! The data you are using, <a href=\"http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html\">notMNIST</a>, consists of images of a letter from A to J in differents font.\n",
    "\n",
    "The above images are a few examples of the data you'll be training on. After training the network, you will compare your prediction model against test data. Your goal, by the end of this lab, is to make predictions against that test set with at least an 80% accuracy. Let's jump in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start this lab, you first need to import all the necessary modules. Run the code below. If it runs successfully, it will print \"`All modules imported`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported.\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import pickle\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "\n",
    "print('All modules imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notMNIST dataset is too large for many computers to handle.  It contains 500,000 images for just training.  You'll be using a subset of this data, 15,000 images for each label (A-J)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files downloaded.\n"
     ]
    }
   ],
   "source": [
    "def download(url, file):\n",
    "    \"\"\"\n",
    "    Download file from <url>\n",
    "    :param url: URL to file\n",
    "    :param file: Local file path\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file):\n",
    "        print('Downloading ' + file + '...')\n",
    "        urlretrieve(url, file)\n",
    "        print('Download Finished')\n",
    "\n",
    "# Download the training and test dataset.\n",
    "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_train.zip', 'notMNIST_train.zip')\n",
    "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_test.zip', 'notMNIST_test.zip')\n",
    "\n",
    "# Make sure the files aren't corrupted\n",
    "assert hashlib.md5(open('notMNIST_train.zip', 'rb').read()).hexdigest() == 'c8673b3f28f489e9cdf3a3d74e2ac8fa',\\\n",
    "        'notMNIST_train.zip file is corrupted.  Remove the file and try again.'\n",
    "assert hashlib.md5(open('notMNIST_test.zip', 'rb').read()).hexdigest() == '5d3c7e653e63471c88df796156a9dfa9',\\\n",
    "        'notMNIST_test.zip file is corrupted.  Remove the file and try again.'\n",
    "\n",
    "# Wait until you see that all files have been downloaded.\n",
    "print('All files downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/210001 [00:00<?, ?files/s]\u001b[A\n",
      "  0%|          | 177/210001 [00:00<01:58, 1767.00files/s]\u001b[A\n",
      "  0%|          | 504/210001 [00:00<01:42, 2048.76files/s]\u001b[A\n",
      "  0%|          | 864/210001 [00:00<01:28, 2352.85files/s]\u001b[A\n",
      "  1%|          | 1231/210001 [00:00<01:19, 2636.48files/s]\u001b[A\n",
      "  1%|          | 1577/210001 [00:00<01:13, 2837.78files/s]\u001b[A\n",
      "  1%|          | 1945/210001 [00:00<01:08, 3044.07files/s]\u001b[A\n",
      "  1%|          | 2321/210001 [00:00<01:04, 3227.76files/s]\u001b[A\n",
      "  1%|▏         | 2688/210001 [00:00<01:01, 3347.32files/s]\u001b[A\n",
      "  1%|▏         | 3059/210001 [00:00<01:00, 3445.11files/s]\u001b[A\n",
      "  2%|▏         | 3434/210001 [00:01<00:58, 3530.51files/s]\u001b[A\n",
      "  2%|▏         | 3791/210001 [00:01<01:00, 3381.79files/s]\u001b[A\n",
      "  2%|▏         | 4135/210001 [00:01<01:00, 3396.40files/s]\u001b[A\n",
      "  2%|▏         | 4498/210001 [00:01<00:59, 3459.57files/s]\u001b[A\n",
      "  2%|▏         | 4846/210001 [00:01<00:59, 3449.31files/s]\u001b[A\n",
      "  2%|▏         | 5199/210001 [00:01<00:59, 3469.91files/s]\u001b[A\n",
      "  3%|▎         | 5561/210001 [00:01<00:58, 3511.21files/s]\u001b[A\n",
      "  3%|▎         | 5913/210001 [00:01<00:58, 3465.30files/s]\u001b[A\n",
      "  3%|▎         | 6261/210001 [00:01<01:02, 3254.58files/s]\u001b[A\n",
      "  3%|▎         | 6590/210001 [00:01<01:04, 3168.26files/s]\u001b[A\n",
      "  3%|▎         | 6957/210001 [00:02<01:01, 3300.07files/s]\u001b[A\n",
      "  3%|▎         | 7316/210001 [00:02<00:59, 3379.94files/s]\u001b[A\n",
      "  4%|▎         | 7687/210001 [00:02<00:58, 3469.57files/s]\u001b[A\n",
      "  4%|▍         | 8073/210001 [00:02<00:56, 3577.08files/s]\u001b[A\n",
      "  4%|▍         | 8436/210001 [00:02<00:56, 3592.14files/s]\u001b[A\n",
      "  4%|▍         | 8812/210001 [00:02<00:55, 3638.51files/s]\u001b[A\n",
      "  4%|▍         | 9192/210001 [00:02<00:54, 3684.12files/s]\u001b[A\n",
      "  5%|▍         | 9569/210001 [00:02<00:54, 3708.61files/s]\u001b[A\n",
      "  5%|▍         | 9958/210001 [00:02<00:53, 3759.99files/s]\u001b[A\n",
      "  5%|▍         | 10335/210001 [00:02<00:53, 3734.41files/s]\u001b[A\n",
      "  5%|▌         | 10710/210001 [00:03<00:53, 3712.95files/s]\u001b[A\n",
      "  5%|▌         | 11082/210001 [00:03<00:56, 3522.00files/s]\u001b[A\n",
      "  5%|▌         | 11437/210001 [00:03<00:56, 3529.97files/s]\u001b[A\n",
      "  6%|▌         | 11810/210001 [00:03<00:55, 3587.06files/s]\u001b[A\n",
      "  6%|▌         | 12181/210001 [00:03<00:54, 3622.23files/s]\u001b[A\n",
      "  6%|▌         | 12546/210001 [00:03<00:54, 3628.66files/s]\u001b[A\n",
      "  6%|▌         | 12910/210001 [00:03<00:54, 3602.83files/s]\u001b[A\n",
      "  6%|▋         | 13280/210001 [00:03<00:54, 3630.65files/s]\u001b[A\n",
      "  6%|▋         | 13644/210001 [00:03<00:56, 3505.61files/s]\u001b[A\n",
      "  7%|▋         | 13996/210001 [00:04<00:58, 3337.98files/s]\u001b[A\n",
      "  7%|▋         | 14333/210001 [00:04<00:59, 3268.07files/s]\u001b[A\n",
      "  7%|▋         | 14683/210001 [00:04<00:58, 3332.63files/s]\u001b[A\n",
      "  7%|▋         | 15055/210001 [00:04<00:56, 3439.67files/s]\u001b[A\n",
      "  7%|▋         | 15427/210001 [00:04<00:55, 3512.68files/s]\u001b[A\n",
      "  8%|▊         | 15781/210001 [00:04<00:55, 3471.05files/s]\u001b[A\n",
      "  8%|▊         | 16130/210001 [00:04<00:56, 3411.57files/s]\u001b[A\n",
      "  8%|▊         | 16473/210001 [00:04<00:57, 3366.15files/s]\u001b[A\n",
      "  8%|▊         | 16811/210001 [00:04<00:57, 3353.41files/s]\u001b[A\n",
      "  8%|▊         | 17159/210001 [00:04<00:56, 3389.38files/s]\u001b[A\n",
      "  8%|▊         | 17501/210001 [00:05<00:56, 3397.01files/s]\u001b[A\n",
      "  8%|▊         | 17842/210001 [00:05<00:59, 3254.27files/s]\u001b[A\n",
      "  9%|▊         | 18169/210001 [00:05<01:01, 3136.78files/s]\u001b[A\n",
      "  9%|▉         | 18501/210001 [00:05<01:00, 3186.22files/s]\u001b[A\n",
      "  9%|▉         | 18825/210001 [00:05<01:00, 3182.89files/s]\u001b[A\n",
      "  9%|▉         | 19145/210001 [00:05<01:02, 3077.59files/s]\u001b[A\n",
      "  9%|▉         | 19457/210001 [00:05<01:01, 3088.99files/s]\u001b[A\n",
      "  9%|▉         | 19767/210001 [00:05<01:03, 3001.26files/s]\u001b[A\n",
      " 10%|▉         | 20077/210001 [00:05<01:02, 3029.99files/s]\u001b[A\n",
      " 10%|▉         | 20408/210001 [00:05<01:01, 3105.99files/s]\u001b[A\n",
      " 10%|▉         | 20720/210001 [00:06<01:01, 3060.35files/s]\u001b[A\n",
      " 10%|█         | 21027/210001 [00:06<01:05, 2891.39files/s]\u001b[A\n",
      " 10%|█         | 21370/210001 [00:06<01:02, 3033.73files/s]\u001b[A\n",
      " 10%|█         | 21678/210001 [00:06<01:03, 2947.62files/s]\u001b[A\n",
      " 10%|█         | 21976/210001 [00:06<01:04, 2914.18files/s]\u001b[A\n",
      " 11%|█         | 22270/210001 [00:06<01:05, 2862.75files/s]\u001b[A\n",
      " 11%|█         | 22559/210001 [00:06<01:07, 2776.23files/s]\u001b[A\n",
      " 11%|█         | 22839/210001 [00:06<01:08, 2718.68files/s]\u001b[A\n",
      " 11%|█         | 23113/210001 [00:06<01:09, 2700.42files/s]\u001b[A\n",
      " 11%|█         | 23385/210001 [00:07<01:12, 2580.32files/s]\u001b[A\n",
      " 11%|█▏        | 23697/210001 [00:07<01:08, 2721.41files/s]\u001b[A\n",
      " 11%|█▏        | 24041/210001 [00:07<01:04, 2901.06files/s]\u001b[A\n",
      " 12%|█▏        | 24383/210001 [00:07<01:01, 3037.64files/s]\u001b[A\n",
      " 12%|█▏        | 24711/210001 [00:07<00:59, 3105.84files/s]\u001b[A\n",
      " 12%|█▏        | 25026/210001 [00:07<01:01, 3002.47files/s]\u001b[A\n",
      " 12%|█▏        | 25382/210001 [00:07<00:58, 3150.08files/s]\u001b[A\n",
      " 12%|█▏        | 25726/210001 [00:07<00:57, 3231.09files/s]\u001b[A\n",
      " 12%|█▏        | 26091/210001 [00:07<00:55, 3342.75files/s]\u001b[A\n",
      " 13%|█▎        | 26461/210001 [00:07<00:53, 3442.12files/s]\u001b[A\n",
      " 13%|█▎        | 26809/210001 [00:08<00:55, 3315.55files/s]\u001b[A\n",
      " 13%|█▎        | 27163/210001 [00:08<00:54, 3377.85files/s]\u001b[A\n",
      " 13%|█▎        | 27523/210001 [00:08<00:53, 3437.52files/s]\u001b[A\n",
      " 13%|█▎        | 27869/210001 [00:08<00:54, 3359.54files/s]\u001b[A\n",
      " 13%|█▎        | 28217/210001 [00:08<00:53, 3392.68files/s]\u001b[A\n",
      " 14%|█▎        | 28597/210001 [00:08<00:51, 3488.74files/s]\u001b[A\n",
      " 14%|█▍        | 28963/210001 [00:08<00:51, 3535.85files/s]\u001b[A\n",
      " 14%|█▍        | 29341/210001 [00:08<00:50, 3603.27files/s]\u001b[A\n",
      " 14%|█▍        | 29703/210001 [00:08<00:51, 3485.29files/s]\u001b[A\n",
      " 14%|█▍        | 30054/210001 [00:09<00:52, 3422.06files/s]\u001b[A\n",
      " 14%|█▍        | 30398/210001 [00:09<00:53, 3343.85files/s]\u001b[A\n",
      " 15%|█▍        | 30734/210001 [00:09<00:53, 3344.46files/s]\u001b[A\n",
      " 15%|█▍        | 31070/210001 [00:09<00:54, 3272.16files/s]\u001b[A\n",
      " 15%|█▍        | 31399/210001 [00:09<00:55, 3202.53files/s]\u001b[A\n",
      " 15%|█▌        | 31721/210001 [00:09<00:56, 3143.43files/s]\u001b[A\n",
      " 15%|█▌        | 32076/210001 [00:09<00:54, 3254.07files/s]\u001b[A\n",
      " 15%|█▌        | 32440/210001 [00:09<00:52, 3360.33files/s]\u001b[A\n",
      " 16%|█▌        | 32779/210001 [00:09<00:52, 3355.22files/s]\u001b[A\n",
      " 16%|█▌        | 33116/210001 [00:09<00:52, 3338.95files/s]\u001b[A\n",
      " 16%|█▌        | 33455/210001 [00:10<00:52, 3349.34files/s]\u001b[A\n",
      " 16%|█▌        | 33798/210001 [00:10<00:52, 3368.66files/s]\u001b[A\n",
      " 16%|█▋        | 34136/210001 [00:10<00:53, 3261.37files/s]\u001b[A\n",
      " 16%|█▋        | 34464/210001 [00:10<00:54, 3194.05files/s]\u001b[A\n",
      " 17%|█▋        | 34785/210001 [00:10<00:55, 3135.54files/s]\u001b[A\n",
      " 17%|█▋        | 35124/210001 [00:10<00:54, 3207.69files/s]\u001b[A\n",
      " 17%|█▋        | 35482/210001 [00:10<00:52, 3310.27files/s]\u001b[A\n",
      " 17%|█▋        | 35815/210001 [00:10<00:53, 3274.51files/s]\u001b[A\n",
      " 17%|█▋        | 36166/210001 [00:10<00:52, 3336.90files/s]\u001b[A\n",
      " 17%|█▋        | 36502/210001 [00:11<00:51, 3342.01files/s]\u001b[A\n",
      " 18%|█▊        | 36862/210001 [00:11<00:50, 3411.02files/s]\u001b[A\n",
      " 18%|█▊        | 37210/210001 [00:11<00:50, 3429.22files/s]\u001b[A\n",
      " 18%|█▊        | 37565/210001 [00:11<00:49, 3461.87files/s]\u001b[A\n",
      " 18%|█▊        | 37912/210001 [00:11<00:55, 3124.53files/s]\u001b[A\n",
      " 18%|█▊        | 38232/210001 [00:11<01:00, 2856.58files/s]\u001b[A\n",
      " 18%|█▊        | 38527/210001 [00:11<01:09, 2460.91files/s]\u001b[A\n",
      " 19%|█▊        | 38886/210001 [00:11<01:02, 2716.20files/s]\u001b[A\n",
      " 19%|█▊        | 39260/210001 [00:11<00:57, 2959.19files/s]\u001b[A\n",
      " 19%|█▉        | 39636/210001 [00:12<00:53, 3158.53files/s]\u001b[A\n",
      " 19%|█▉        | 39991/210001 [00:12<00:52, 3264.78files/s]\u001b[A\n",
      " 19%|█▉        | 40331/210001 [00:12<01:00, 2782.08files/s]\u001b[A\n",
      " 19%|█▉        | 40631/210001 [00:12<01:04, 2611.64files/s]\u001b[A\n",
      " 19%|█▉        | 40910/210001 [00:12<01:08, 2458.00files/s]\u001b[A\n",
      " 20%|█▉        | 41170/210001 [00:12<01:11, 2366.91files/s]\u001b[A\n",
      " 20%|█▉        | 41418/210001 [00:12<01:13, 2287.41files/s]\u001b[A\n",
      " 20%|█▉        | 41668/210001 [00:12<01:11, 2346.77files/s]\u001b[A\n",
      " 20%|█▉        | 41909/210001 [00:13<01:15, 2229.12files/s]\u001b[A\n",
      " 20%|██        | 42248/210001 [00:13<01:07, 2482.90files/s]\u001b[A\n",
      " 20%|██        | 42560/210001 [00:13<01:03, 2640.59files/s]\u001b[A\n",
      " 20%|██        | 42927/210001 [00:13<00:57, 2880.86files/s]\u001b[A\n",
      " 21%|██        | 43280/210001 [00:13<00:54, 3048.97files/s]\u001b[A\n",
      " 21%|██        | 43633/210001 [00:13<00:52, 3177.63files/s]\u001b[A\n",
      " 21%|██        | 44030/210001 [00:13<00:49, 3378.44files/s]\u001b[A\n",
      " 21%|██        | 44384/210001 [00:13<00:48, 3422.43files/s]\u001b[A\n",
      " 21%|██▏       | 44750/210001 [00:13<00:47, 3484.53files/s]\u001b[A\n",
      " 21%|██▏       | 45114/210001 [00:13<00:46, 3528.07files/s]\u001b[A\n",
      " 22%|██▏       | 45471/210001 [00:14<00:51, 3167.39files/s]\u001b[A\n",
      " 22%|██▏       | 45798/210001 [00:14<01:02, 2645.45files/s]\u001b[A\n",
      " 22%|██▏       | 46084/210001 [00:14<01:02, 2619.26files/s]\u001b[A\n",
      " 22%|██▏       | 46374/210001 [00:14<01:00, 2697.15files/s]\u001b[A\n",
      " 22%|██▏       | 46655/210001 [00:14<01:01, 2636.14files/s]\u001b[A\n",
      " 22%|██▏       | 46927/210001 [00:14<01:09, 2348.40files/s]\u001b[A\n",
      " 22%|██▏       | 47245/210001 [00:14<01:03, 2547.08files/s]\u001b[A\n",
      " 23%|██▎       | 47610/210001 [00:14<00:58, 2798.86files/s]\u001b[A\n",
      " 23%|██▎       | 47998/210001 [00:15<00:53, 3046.13files/s]\u001b[A\n",
      " 23%|██▎       | 48381/210001 [00:15<00:49, 3242.60files/s]\u001b[A\n",
      " 23%|██▎       | 48763/210001 [00:15<00:47, 3396.30files/s]\u001b[A\n",
      " 23%|██▎       | 49128/210001 [00:15<00:46, 3466.31files/s]\u001b[A\n",
      " 24%|██▎       | 49485/210001 [00:15<00:46, 3471.09files/s]\u001b[A\n",
      " 24%|██▎       | 49839/210001 [00:15<00:46, 3444.80files/s]\u001b[A\n",
      " 24%|██▍       | 50189/210001 [00:15<00:46, 3440.63files/s]\u001b[A\n",
      " 24%|██▍       | 50537/210001 [00:15<00:46, 3431.11files/s]\u001b[A\n",
      " 24%|██▍       | 50885/210001 [00:15<00:46, 3443.12files/s]\u001b[A\n",
      " 24%|██▍       | 51231/210001 [00:15<00:52, 3010.51files/s]\u001b[A\n",
      " 25%|██▍       | 51544/210001 [00:16<00:53, 2978.20files/s]\u001b[A\n",
      " 25%|██▍       | 51889/210001 [00:16<00:50, 3104.90files/s]\u001b[A\n",
      " 25%|██▍       | 52267/210001 [00:16<00:48, 3279.24files/s]\u001b[A\n",
      " 25%|██▌       | 52639/210001 [00:16<00:46, 3397.02files/s]\u001b[A\n",
      " 25%|██▌       | 53002/210001 [00:16<00:45, 3462.00files/s]\u001b[A\n",
      " 25%|██▌       | 53387/210001 [00:16<00:43, 3567.12files/s]\u001b[A\n",
      " 26%|██▌       | 53770/210001 [00:16<00:42, 3640.69files/s]\u001b[A\n",
      " 26%|██▌       | 54138/210001 [00:16<00:43, 3559.98files/s]\u001b[A\n",
      " 26%|██▌       | 54521/210001 [00:16<00:42, 3635.48files/s]\u001b[A\n",
      " 26%|██▌       | 54913/210001 [00:16<00:41, 3714.35files/s]\u001b[A\n",
      " 26%|██▋       | 55287/210001 [00:17<00:42, 3660.04files/s]\u001b[A\n",
      " 27%|██▋       | 55655/210001 [00:17<00:42, 3653.67files/s]\u001b[A\n",
      " 27%|██▋       | 56038/210001 [00:17<00:41, 3701.97files/s]\u001b[A\n",
      " 27%|██▋       | 56426/210001 [00:17<00:40, 3750.84files/s]\u001b[A\n",
      " 27%|██▋       | 56802/210001 [00:17<00:40, 3749.00files/s]\u001b[A\n",
      " 27%|██▋       | 57193/210001 [00:17<00:40, 3794.92files/s]\u001b[A\n",
      " 27%|██▋       | 57586/210001 [00:17<00:39, 3830.59files/s]\u001b[A\n",
      " 28%|██▊       | 57970/210001 [00:17<00:39, 3801.43files/s]\u001b[A\n",
      " 28%|██▊       | 58359/210001 [00:17<00:39, 3825.84files/s]\u001b[A\n",
      " 28%|██▊       | 58750/210001 [00:17<00:39, 3848.90files/s]\u001b[A\n",
      " 28%|██▊       | 59136/210001 [00:18<00:39, 3843.33files/s]\u001b[A\n",
      " 28%|██▊       | 59521/210001 [00:18<00:39, 3836.67files/s]\u001b[A\n",
      " 29%|██▊       | 59905/210001 [00:18<00:39, 3764.68files/s]\u001b[A\n",
      " 29%|██▊       | 60284/210001 [00:18<00:39, 3770.97files/s]\u001b[A\n",
      " 29%|██▉       | 60672/210001 [00:18<00:39, 3800.11files/s]\u001b[A\n",
      " 29%|██▉       | 61053/210001 [00:18<00:45, 3250.95files/s]\u001b[A\n",
      " 29%|██▉       | 61393/210001 [00:18<00:54, 2728.85files/s]\u001b[A\n",
      " 29%|██▉       | 61713/210001 [00:18<00:51, 2853.31files/s]\u001b[A\n",
      " 30%|██▉       | 62111/210001 [00:19<00:47, 3116.41files/s]\u001b[A\n",
      " 30%|██▉       | 62500/210001 [00:19<00:44, 3313.53files/s]\u001b[A\n",
      " 30%|██▉       | 62888/210001 [00:19<00:42, 3465.13files/s]\u001b[A\n",
      " 30%|███       | 63249/210001 [00:19<00:47, 3088.89files/s]\u001b[A\n",
      " 30%|███       | 63576/210001 [00:19<00:54, 2682.62files/s]\u001b[A\n",
      " 30%|███       | 63866/210001 [00:19<00:56, 2566.82files/s]\u001b[A\n",
      " 31%|███       | 64164/210001 [00:19<00:54, 2677.38files/s]\u001b[A\n",
      " 31%|███       | 64521/210001 [00:19<00:50, 2890.77files/s]\u001b[A\n",
      " 31%|███       | 64862/210001 [00:19<00:47, 3028.19files/s]\u001b[A\n",
      " 31%|███       | 65258/210001 [00:20<00:44, 3258.15files/s]\u001b[A\n",
      " 31%|███       | 65604/210001 [00:20<00:43, 3313.92files/s]\u001b[A\n",
      " 31%|███▏      | 65969/210001 [00:20<00:42, 3401.97files/s]\u001b[A\n",
      " 32%|███▏      | 66317/210001 [00:20<00:43, 3305.15files/s]\u001b[A\n",
      " 32%|███▏      | 66654/210001 [00:20<00:44, 3247.91files/s]\u001b[A\n",
      " 32%|███▏      | 67026/210001 [00:20<00:42, 3376.41files/s]\u001b[A\n",
      " 32%|███▏      | 67409/210001 [00:20<00:40, 3497.74files/s]\u001b[A\n",
      " 32%|███▏      | 67783/210001 [00:20<00:39, 3566.02files/s]\u001b[A\n",
      " 32%|███▏      | 68166/210001 [00:20<00:38, 3639.89files/s]\u001b[A\n",
      " 33%|███▎      | 68533/210001 [00:20<00:39, 3569.93files/s]\u001b[A\n",
      " 33%|███▎      | 68896/210001 [00:21<00:39, 3587.49files/s]\u001b[A\n",
      " 33%|███▎      | 69280/210001 [00:21<00:38, 3659.53files/s]\u001b[A\n",
      " 33%|███▎      | 69664/210001 [00:21<00:37, 3708.84files/s]\u001b[A\n",
      " 33%|███▎      | 70044/210001 [00:21<00:37, 3735.47files/s]\u001b[A\n",
      " 34%|███▎      | 70419/210001 [00:21<00:37, 3728.81files/s]\u001b[A\n",
      " 34%|███▎      | 70793/210001 [00:21<00:37, 3691.92files/s]\u001b[A\n",
      " 34%|███▍      | 71163/210001 [00:21<00:38, 3650.14files/s]\u001b[A\n",
      " 34%|███▍      | 71529/210001 [00:21<00:39, 3491.75files/s]\u001b[A\n",
      " 34%|███▍      | 71880/210001 [00:21<00:42, 3227.72files/s]\u001b[A\n",
      " 34%|███▍      | 72208/210001 [00:22<00:47, 2874.79files/s]\u001b[A\n",
      " 35%|███▍      | 72507/210001 [00:22<00:51, 2671.46files/s]\u001b[A\n",
      " 35%|███▍      | 72838/210001 [00:22<00:48, 2833.92files/s]\u001b[A\n",
      " 35%|███▍      | 73132/210001 [00:22<00:53, 2540.46files/s]\u001b[A\n",
      " 35%|███▍      | 73399/210001 [00:22<00:56, 2404.98files/s]\u001b[A\n",
      " 35%|███▌      | 73650/210001 [00:22<00:56, 2430.27files/s]\u001b[A\n",
      " 35%|███▌      | 73921/210001 [00:22<00:54, 2502.81files/s]\u001b[A\n",
      " 35%|███▌      | 74180/210001 [00:22<00:53, 2523.66files/s]\u001b[A\n",
      " 35%|███▌      | 74446/210001 [00:22<00:52, 2559.05files/s]\u001b[A\n",
      " 36%|███▌      | 74705/210001 [00:23<00:55, 2456.76files/s]\u001b[A\n",
      " 36%|███▌      | 75050/210001 [00:23<00:50, 2687.79files/s]\u001b[A\n",
      " 36%|███▌      | 75406/210001 [00:23<00:46, 2898.89files/s]\u001b[A\n",
      " 36%|███▌      | 75772/210001 [00:23<00:43, 3089.36files/s]\u001b[A\n",
      " 36%|███▌      | 76092/210001 [00:23<00:43, 3070.40files/s]\u001b[A\n",
      " 36%|███▋      | 76407/210001 [00:23<00:44, 3021.69files/s]\u001b[A\n",
      " 37%|███▋      | 76746/210001 [00:23<00:42, 3119.74files/s]\u001b[A\n",
      " 37%|███▋      | 77110/210001 [00:23<00:40, 3257.95files/s]\u001b[A\n",
      " 37%|███▋      | 77475/210001 [00:23<00:39, 3364.46files/s]\u001b[A\n",
      " 37%|███▋      | 77816/210001 [00:24<00:39, 3361.46files/s]\u001b[A\n",
      " 37%|███▋      | 78183/210001 [00:24<00:38, 3448.26files/s]\u001b[A\n",
      " 37%|███▋      | 78546/210001 [00:24<00:37, 3497.82files/s]\u001b[A\n",
      " 38%|███▊      | 78931/210001 [00:24<00:36, 3595.62files/s]\u001b[A\n",
      " 38%|███▊      | 79293/210001 [00:24<00:40, 3232.03files/s]\u001b[A\n",
      " 38%|███▊      | 79650/210001 [00:24<00:39, 3325.47files/s]\u001b[A\n",
      " 38%|███▊      | 79994/210001 [00:24<00:38, 3356.56files/s]\u001b[A\n",
      " 38%|███▊      | 80335/210001 [00:24<00:38, 3325.90files/s]\u001b[A\n",
      " 38%|███▊      | 80684/210001 [00:24<00:38, 3372.37files/s]\u001b[A\n",
      " 39%|███▊      | 81066/210001 [00:24<00:36, 3488.31files/s]\u001b[A\n",
      " 39%|███▉      | 81458/210001 [00:25<00:35, 3600.64files/s]\u001b[A\n",
      " 39%|███▉      | 81869/210001 [00:25<00:34, 3736.30files/s]\u001b[A\n",
      " 39%|███▉      | 82264/210001 [00:25<00:33, 3797.37files/s]\u001b[A\n",
      " 39%|███▉      | 82661/210001 [00:25<00:33, 3845.19files/s]\u001b[A\n",
      " 40%|███▉      | 83048/210001 [00:25<00:33, 3787.60files/s]\u001b[A\n",
      " 40%|███▉      | 83429/210001 [00:25<00:34, 3699.82files/s]\u001b[A\n",
      " 40%|███▉      | 83801/210001 [00:25<00:34, 3637.78files/s]\u001b[A\n",
      " 40%|████      | 84167/210001 [00:25<00:34, 3599.85files/s]\u001b[A\n",
      " 40%|████      | 84528/210001 [00:25<00:36, 3460.07files/s]\u001b[A\n",
      " 40%|████      | 84876/210001 [00:26<00:36, 3412.99files/s]\u001b[A\n",
      " 41%|████      | 85219/210001 [00:26<00:37, 3346.98files/s]\u001b[A\n",
      " 41%|████      | 85590/210001 [00:26<00:36, 3447.79files/s]\u001b[A\n",
      " 41%|████      | 85961/210001 [00:26<00:35, 3521.71files/s]\u001b[A\n",
      " 41%|████      | 86333/210001 [00:26<00:34, 3578.01files/s]\u001b[A\n",
      " 41%|████▏     | 86719/210001 [00:26<00:33, 3656.76files/s]\u001b[A\n",
      " 41%|████▏     | 87122/210001 [00:26<00:32, 3760.27files/s]\u001b[A\n",
      " 42%|████▏     | 87509/210001 [00:26<00:32, 3789.35files/s]\u001b[A\n",
      " 42%|████▏     | 87890/210001 [00:26<00:33, 3683.80files/s]\u001b[A\n",
      " 42%|████▏     | 88260/210001 [00:26<00:34, 3508.02files/s]\u001b[A\n",
      " 42%|████▏     | 88614/210001 [00:27<00:40, 2991.32files/s]\u001b[A\n",
      " 42%|████▏     | 88929/210001 [00:27<00:40, 3024.61files/s]\u001b[A\n",
      " 42%|████▏     | 89243/210001 [00:27<00:39, 3041.76files/s]\u001b[A\n",
      " 43%|████▎     | 89555/210001 [00:27<00:39, 3035.79files/s]\u001b[A\n",
      " 43%|████▎     | 89882/210001 [00:27<00:38, 3100.91files/s]\u001b[A\n",
      " 43%|████▎     | 90270/210001 [00:27<00:36, 3297.15files/s]\u001b[A\n",
      " 43%|████▎     | 90661/210001 [00:27<00:34, 3459.04files/s]\u001b[A\n",
      " 43%|████▎     | 91050/210001 [00:27<00:33, 3575.85files/s]\u001b[A\n",
      " 44%|████▎     | 91438/210001 [00:27<00:32, 3658.62files/s]\u001b[A\n",
      " 44%|████▎     | 91826/210001 [00:28<00:31, 3710.70files/s]\u001b[A\n",
      " 44%|████▍     | 92207/210001 [00:28<00:31, 3736.59files/s]\u001b[A\n",
      " 44%|████▍     | 92602/210001 [00:28<00:30, 3792.42files/s]\u001b[A\n",
      " 44%|████▍     | 92984/210001 [00:28<00:30, 3790.30files/s]\u001b[A\n",
      " 44%|████▍     | 93365/210001 [00:28<00:30, 3773.03files/s]\u001b[A\n",
      " 45%|████▍     | 93744/210001 [00:28<00:30, 3759.05files/s]\u001b[A\n",
      " 45%|████▍     | 94121/210001 [00:28<00:31, 3643.80files/s]\u001b[A\n",
      " 45%|████▍     | 94487/210001 [00:28<00:32, 3582.85files/s]\u001b[A\n",
      " 45%|████▌     | 94876/210001 [00:28<00:31, 3667.56files/s]\u001b[A\n",
      " 45%|████▌     | 95269/210001 [00:28<00:30, 3742.31files/s]\u001b[A\n",
      " 46%|████▌     | 95645/210001 [00:29<00:31, 3589.79files/s]\u001b[A\n",
      " 46%|████▌     | 96012/210001 [00:29<00:31, 3611.50files/s]\u001b[A\n",
      " 46%|████▌     | 96389/210001 [00:29<00:31, 3652.80files/s]\u001b[A\n",
      " 46%|████▌     | 96757/210001 [00:29<00:30, 3659.82files/s]\u001b[A\n",
      " 46%|████▋     | 97131/210001 [00:29<00:30, 3682.98files/s]\u001b[A\n",
      " 46%|████▋     | 97500/210001 [00:29<00:30, 3641.76files/s]\u001b[A\n",
      " 47%|████▋     | 97868/210001 [00:29<00:30, 3652.52files/s]\u001b[A\n",
      " 47%|████▋     | 98253/210001 [00:29<00:30, 3708.26files/s]\u001b[A\n",
      " 47%|████▋     | 98625/210001 [00:29<00:31, 3579.81files/s]\u001b[A\n",
      " 47%|████▋     | 98985/210001 [00:29<00:31, 3487.76files/s]\u001b[A\n",
      " 47%|████▋     | 99336/210001 [00:30<00:32, 3435.15files/s]\u001b[A\n",
      " 47%|████▋     | 99716/210001 [00:30<00:31, 3536.94files/s]\u001b[A\n",
      " 48%|████▊     | 100072/210001 [00:30<00:36, 2985.70files/s]\u001b[A\n",
      " 48%|████▊     | 100387/210001 [00:30<00:42, 2568.81files/s]\u001b[A\n",
      " 48%|████▊     | 100666/210001 [00:30<00:42, 2578.01files/s]\u001b[A\n",
      " 48%|████▊     | 100939/210001 [00:30<00:42, 2583.77files/s]\u001b[A\n",
      " 48%|████▊     | 101265/210001 [00:30<00:39, 2754.33files/s]\u001b[A\n",
      " 48%|████▊     | 101623/210001 [00:30<00:36, 2958.52files/s]\u001b[A\n",
      " 49%|████▊     | 102028/210001 [00:31<00:33, 3217.71files/s]\u001b[A\n",
      " 49%|████▉     | 102429/210001 [00:31<00:31, 3418.65files/s]\u001b[A\n",
      " 49%|████▉     | 102825/210001 [00:31<00:30, 3563.41files/s]\u001b[A\n",
      " 49%|████▉     | 103193/210001 [00:31<00:30, 3535.19files/s]\u001b[A\n",
      " 49%|████▉     | 103582/210001 [00:31<00:29, 3634.61files/s]\u001b[A\n",
      " 50%|████▉     | 103968/210001 [00:31<00:28, 3690.05files/s]\u001b[A\n",
      " 50%|████▉     | 104342/210001 [00:31<00:29, 3622.71files/s]\u001b[A\n",
      " 50%|████▉     | 104731/210001 [00:31<00:28, 3697.74files/s]\u001b[A\n",
      " 50%|█████     | 105110/210001 [00:31<00:28, 3724.82files/s]\u001b[A\n",
      " 50%|█████     | 105485/210001 [00:31<00:29, 3565.50files/s]\u001b[A\n",
      " 50%|█████     | 105845/210001 [00:32<00:35, 2941.81files/s]\u001b[A\n",
      " 51%|█████     | 106160/210001 [00:32<00:38, 2680.02files/s]\u001b[A\n",
      " 51%|█████     | 106447/210001 [00:32<00:41, 2477.50files/s]\u001b[A\n",
      " 51%|█████     | 106769/210001 [00:32<00:38, 2660.29files/s]\u001b[A\n",
      " 51%|█████     | 107132/210001 [00:32<00:35, 2891.93files/s]\u001b[A\n",
      " 51%|█████     | 107493/210001 [00:32<00:33, 3070.66files/s]\u001b[A\n",
      " 51%|█████▏    | 107841/210001 [00:32<00:32, 3181.34files/s]\u001b[A\n",
      " 52%|█████▏    | 108171/210001 [00:32<00:36, 2774.44files/s]\u001b[A\n",
      " 52%|█████▏    | 108466/210001 [00:33<00:41, 2474.78files/s]\u001b[A\n",
      " 52%|█████▏    | 108732/210001 [00:33<00:42, 2388.82files/s]\u001b[A\n",
      " 52%|█████▏    | 108985/210001 [00:33<00:44, 2245.54files/s]\u001b[A\n",
      " 52%|█████▏    | 109221/210001 [00:33<00:45, 2229.06files/s]\u001b[A\n",
      " 52%|█████▏    | 109506/210001 [00:33<00:42, 2384.17files/s]\u001b[A\n",
      " 52%|█████▏    | 109836/210001 [00:33<00:38, 2599.47files/s]\u001b[A\n",
      " 52%|█████▏    | 110173/210001 [00:33<00:35, 2789.36files/s]\u001b[A\n",
      " 53%|█████▎    | 110519/210001 [00:33<00:33, 2959.32files/s]\u001b[A\n",
      " 53%|█████▎    | 110848/210001 [00:33<00:32, 3048.92files/s]\u001b[A\n",
      " 53%|█████▎    | 111167/210001 [00:34<00:32, 3087.43files/s]\u001b[A\n",
      " 53%|█████▎    | 111531/210001 [00:34<00:30, 3233.68files/s]\u001b[A\n",
      " 53%|█████▎    | 111881/210001 [00:34<00:29, 3303.57files/s]\u001b[A\n",
      " 53%|█████▎    | 112259/210001 [00:34<00:28, 3432.11files/s]\u001b[A\n",
      " 54%|█████▎    | 112642/210001 [00:34<00:27, 3541.97files/s]\u001b[A\n",
      " 54%|█████▍    | 113016/210001 [00:34<00:26, 3595.70files/s]\u001b[A\n",
      " 54%|█████▍    | 113398/210001 [00:34<00:26, 3658.62files/s]\u001b[A\n",
      " 54%|█████▍    | 113767/210001 [00:34<00:26, 3635.16files/s]\u001b[A\n",
      " 54%|█████▍    | 114160/210001 [00:34<00:25, 3716.01files/s]\u001b[A\n",
      " 55%|█████▍    | 114546/210001 [00:34<00:25, 3753.89files/s]\u001b[A\n",
      " 55%|█████▍    | 114923/210001 [00:35<00:26, 3627.35files/s]\u001b[A\n",
      " 55%|█████▍    | 115307/210001 [00:35<00:25, 3686.18files/s]\u001b[A\n",
      " 55%|█████▌    | 115678/210001 [00:35<00:29, 3197.52files/s]\u001b[A\n",
      " 55%|█████▌    | 116044/210001 [00:35<00:28, 3322.16files/s]\u001b[A\n",
      " 55%|█████▌    | 116425/210001 [00:35<00:27, 3453.67files/s]\u001b[A\n",
      " 56%|█████▌    | 116788/210001 [00:35<00:26, 3503.38files/s]\u001b[A\n",
      " 56%|█████▌    | 117155/210001 [00:35<00:26, 3549.47files/s]\u001b[A\n",
      " 56%|█████▌    | 117515/210001 [00:35<00:26, 3436.63files/s]\u001b[A\n",
      " 56%|█████▌    | 117863/210001 [00:35<00:27, 3326.15files/s]\u001b[A\n",
      " 56%|█████▋    | 118200/210001 [00:36<00:28, 3268.82files/s]\u001b[A\n",
      " 56%|█████▋    | 118530/210001 [00:36<00:28, 3198.15files/s]\u001b[A\n",
      " 57%|█████▋    | 118910/210001 [00:36<00:27, 3357.12files/s]\u001b[A\n",
      " 57%|█████▋    | 119292/210001 [00:36<00:26, 3482.28files/s]\u001b[A\n",
      " 57%|█████▋    | 119668/210001 [00:36<00:25, 3557.68files/s]\u001b[A\n",
      " 57%|█████▋    | 120062/210001 [00:36<00:24, 3663.75files/s]\u001b[A\n",
      " 57%|█████▋    | 120432/210001 [00:36<00:24, 3645.13files/s]\u001b[A\n",
      " 58%|█████▊    | 120803/210001 [00:36<00:24, 3664.29files/s]\u001b[A\n",
      " 58%|█████▊    | 121171/210001 [00:36<00:28, 3151.09files/s]\u001b[A\n",
      " 58%|█████▊    | 121538/210001 [00:37<00:26, 3288.84files/s]\u001b[A\n",
      " 58%|█████▊    | 121896/210001 [00:37<00:26, 3368.72files/s]\u001b[A\n",
      " 58%|█████▊    | 122242/210001 [00:37<00:26, 3332.73files/s]\u001b[A\n",
      " 58%|█████▊    | 122627/210001 [00:37<00:25, 3471.02files/s]\u001b[A\n",
      " 59%|█████▊    | 123021/210001 [00:37<00:24, 3597.86files/s]\u001b[A\n",
      " 59%|█████▉    | 123410/210001 [00:37<00:23, 3680.07files/s]\u001b[A\n",
      " 59%|█████▉    | 123783/210001 [00:37<00:24, 3588.97files/s]\u001b[A\n",
      " 59%|█████▉    | 124146/210001 [00:37<00:24, 3494.21files/s]\u001b[A\n",
      " 59%|█████▉    | 124499/210001 [00:37<00:25, 3416.28files/s]\u001b[A\n",
      " 59%|█████▉    | 124844/210001 [00:37<00:25, 3398.02files/s]\u001b[A\n",
      " 60%|█████▉    | 125186/210001 [00:38<00:25, 3366.89files/s]\u001b[A\n",
      " 60%|█████▉    | 125524/210001 [00:38<00:25, 3358.09files/s]\u001b[A\n",
      " 60%|█████▉    | 125868/210001 [00:38<00:24, 3379.85files/s]\u001b[A\n",
      " 60%|██████    | 126207/210001 [00:38<00:25, 3236.70files/s]\u001b[A\n",
      " 60%|██████    | 126533/210001 [00:38<00:25, 3236.68files/s]\u001b[A\n",
      " 60%|██████    | 126871/210001 [00:38<00:25, 3271.51files/s]\u001b[A\n",
      " 61%|██████    | 127200/210001 [00:38<00:25, 3240.72files/s]\u001b[A\n",
      " 61%|██████    | 127525/210001 [00:38<00:25, 3212.86files/s]\u001b[A\n",
      " 61%|██████    | 127860/210001 [00:38<00:25, 3249.71files/s]\u001b[A\n",
      " 61%|██████    | 128205/210001 [00:39<00:24, 3302.11files/s]\u001b[A\n",
      " 61%|██████    | 128536/210001 [00:39<00:24, 3274.70files/s]\u001b[A\n",
      " 61%|██████▏   | 128876/210001 [00:39<00:24, 3309.32files/s]\u001b[A\n",
      " 62%|██████▏   | 129208/210001 [00:39<00:24, 3282.06files/s]\u001b[A\n",
      " 62%|██████▏   | 129544/210001 [00:39<00:24, 3303.58files/s]\u001b[A\n",
      " 62%|██████▏   | 129879/210001 [00:39<00:24, 3314.73files/s]\u001b[A\n",
      " 62%|██████▏   | 130211/210001 [00:39<00:24, 3287.29files/s]\u001b[A\n",
      " 62%|██████▏   | 130543/210001 [00:39<00:24, 3295.50files/s]\u001b[A\n",
      " 62%|██████▏   | 130881/210001 [00:39<00:23, 3317.74files/s]\u001b[A\n",
      " 63%|██████▎   | 131268/210001 [00:39<00:22, 3465.21files/s]\u001b[A\n",
      " 63%|██████▎   | 131666/210001 [00:40<00:21, 3603.96files/s]\u001b[A\n",
      " 63%|██████▎   | 132050/210001 [00:40<00:21, 3668.57files/s]\u001b[A\n",
      " 63%|██████▎   | 132443/210001 [00:40<00:20, 3741.95files/s]\u001b[A\n",
      " 63%|██████▎   | 132829/210001 [00:40<00:20, 3775.32files/s]\u001b[A\n",
      " 63%|██████▎   | 133212/210001 [00:40<00:20, 3788.78files/s]\u001b[A\n",
      " 64%|██████▎   | 133592/210001 [00:40<00:21, 3607.12files/s]\u001b[A\n",
      " 64%|██████▍   | 133976/210001 [00:40<00:20, 3673.24files/s]\u001b[A\n",
      " 64%|██████▍   | 134370/210001 [00:40<00:20, 3747.67files/s]\u001b[A\n",
      " 64%|██████▍   | 134749/210001 [00:40<00:20, 3758.05files/s]\u001b[A\n",
      " 64%|██████▍   | 135133/210001 [00:40<00:19, 3781.23files/s]\u001b[A\n",
      " 65%|██████▍   | 135518/210001 [00:41<00:19, 3799.40files/s]\u001b[A\n",
      " 65%|██████▍   | 135903/210001 [00:41<00:19, 3811.47files/s]\u001b[A\n",
      " 65%|██████▍   | 136294/210001 [00:41<00:19, 3839.16files/s]\u001b[A\n",
      " 65%|██████▌   | 136686/210001 [00:41<00:18, 3859.83files/s]\u001b[A\n",
      " 65%|██████▌   | 137073/210001 [00:41<00:18, 3857.92files/s]\u001b[A\n",
      " 65%|██████▌   | 137459/210001 [00:41<00:18, 3822.14files/s]\u001b[A\n",
      " 66%|██████▌   | 137842/210001 [00:41<00:19, 3794.34files/s]\u001b[A\n",
      " 66%|██████▌   | 138228/210001 [00:41<00:18, 3811.43files/s]\u001b[A\n",
      " 66%|██████▌   | 138610/210001 [00:41<00:19, 3751.38files/s]\u001b[A\n",
      " 66%|██████▌   | 138986/210001 [00:41<00:20, 3509.98files/s]\u001b[A\n",
      " 66%|██████▋   | 139341/210001 [00:42<00:20, 3418.13files/s]\u001b[A\n",
      " 67%|██████▋   | 139686/210001 [00:42<00:20, 3350.49files/s]\u001b[A\n",
      " 67%|██████▋   | 140024/210001 [00:42<00:21, 3319.62files/s]\u001b[A\n",
      " 67%|██████▋   | 140358/210001 [00:42<00:21, 3273.60files/s]\u001b[A\n",
      " 67%|██████▋   | 140687/210001 [00:42<00:21, 3224.51files/s]\u001b[A\n",
      " 67%|██████▋   | 141025/210001 [00:42<00:21, 3266.80files/s]\u001b[A\n",
      " 67%|██████▋   | 141353/210001 [00:42<00:23, 2873.30files/s]\u001b[A\n",
      " 67%|██████▋   | 141655/210001 [00:42<00:23, 2914.52files/s]\u001b[A\n",
      " 68%|██████▊   | 142017/210001 [00:42<00:21, 3095.46files/s]\u001b[A\n",
      " 68%|██████▊   | 142379/210001 [00:43<00:20, 3233.58files/s]\u001b[A\n",
      " 68%|██████▊   | 142759/210001 [00:43<00:19, 3384.23files/s]\u001b[A\n",
      " 68%|██████▊   | 143145/210001 [00:43<00:19, 3511.93files/s]\u001b[A\n",
      " 68%|██████▊   | 143530/210001 [00:43<00:18, 3606.25files/s]\u001b[A\n",
      " 69%|██████▊   | 143897/210001 [00:43<00:18, 3622.12files/s]\u001b[A\n",
      " 69%|██████▊   | 144266/210001 [00:43<00:18, 3641.69files/s]\u001b[A\n",
      " 69%|██████▉   | 144633/210001 [00:43<00:18, 3625.11files/s]\u001b[A\n",
      " 69%|██████▉   | 145006/210001 [00:43<00:17, 3654.59files/s]\u001b[A\n",
      " 69%|██████▉   | 145389/210001 [00:43<00:17, 3701.58files/s]\u001b[A\n",
      " 69%|██████▉   | 145761/210001 [00:43<00:17, 3672.11files/s]\u001b[A\n",
      " 70%|██████▉   | 146129/210001 [00:44<00:17, 3640.91files/s]\u001b[A\n",
      " 70%|██████▉   | 146494/210001 [00:44<00:18, 3479.97files/s]\u001b[A\n",
      " 70%|██████▉   | 146844/210001 [00:44<00:18, 3384.60files/s]\u001b[A\n",
      " 70%|███████   | 147185/210001 [00:44<00:19, 3234.04files/s]\u001b[A\n",
      " 70%|███████   | 147512/210001 [00:44<00:19, 3209.25files/s]\u001b[A\n",
      " 70%|███████   | 147907/210001 [00:44<00:18, 3399.85files/s]\u001b[A\n",
      " 71%|███████   | 148295/210001 [00:44<00:17, 3523.51files/s]\u001b[A\n",
      " 71%|███████   | 148669/210001 [00:44<00:17, 3583.59files/s]\u001b[A\n",
      " 71%|███████   | 149043/210001 [00:44<00:16, 3628.59files/s]\u001b[A\n",
      " 71%|███████   | 149436/210001 [00:45<00:16, 3711.88files/s]\u001b[A\n",
      " 71%|███████▏  | 149823/210001 [00:45<00:16, 3743.39files/s]\u001b[A\n",
      " 72%|███████▏  | 150215/210001 [00:45<00:15, 3793.39files/s]\u001b[A\n",
      " 72%|███████▏  | 150596/210001 [00:45<00:15, 3778.35files/s]\u001b[A\n",
      " 72%|███████▏  | 150982/210001 [00:45<00:15, 3797.87files/s]\u001b[A\n",
      " 72%|███████▏  | 151376/210001 [00:45<00:15, 3832.17files/s]\u001b[A\n",
      " 72%|███████▏  | 151760/210001 [00:45<00:15, 3764.01files/s]\u001b[A\n",
      " 72%|███████▏  | 152138/210001 [00:45<00:15, 3714.19files/s]\u001b[A\n",
      " 73%|███████▎  | 152512/210001 [00:45<00:15, 3719.34files/s]\u001b[A\n",
      " 73%|███████▎  | 152885/210001 [00:45<00:15, 3589.13files/s]\u001b[A\n",
      " 73%|███████▎  | 153246/210001 [00:46<00:16, 3484.98files/s]\u001b[A\n",
      " 73%|███████▎  | 153597/210001 [00:46<00:16, 3391.64files/s]\u001b[A\n",
      " 73%|███████▎  | 153998/210001 [00:46<00:15, 3554.50files/s]\u001b[A\n",
      " 74%|███████▎  | 154379/210001 [00:46<00:15, 3619.35files/s]\u001b[A\n",
      " 74%|███████▎  | 154744/210001 [00:46<00:15, 3618.43files/s]\u001b[A\n",
      " 74%|███████▍  | 155137/210001 [00:46<00:14, 3705.72files/s]\u001b[A\n",
      " 74%|███████▍  | 155510/210001 [00:46<00:14, 3698.63files/s]\u001b[A\n",
      " 74%|███████▍  | 155901/210001 [00:46<00:14, 3758.83files/s]\u001b[A\n",
      " 74%|███████▍  | 156294/210001 [00:46<00:14, 3806.54files/s]\u001b[A\n",
      " 75%|███████▍  | 156693/210001 [00:46<00:13, 3854.19files/s]\u001b[A\n",
      " 75%|███████▍  | 157080/210001 [00:47<00:13, 3815.61files/s]\u001b[A\n",
      " 75%|███████▍  | 157463/210001 [00:47<00:13, 3783.20files/s]\u001b[A\n",
      " 75%|███████▌  | 157844/210001 [00:47<00:13, 3789.39files/s]\u001b[A\n",
      " 75%|███████▌  | 158224/210001 [00:47<00:13, 3742.52files/s]\u001b[A\n",
      " 76%|███████▌  | 158618/210001 [00:47<00:13, 3797.24files/s]\u001b[A\n",
      " 76%|███████▌  | 158999/210001 [00:47<00:13, 3791.54files/s]\u001b[A\n",
      " 76%|███████▌  | 159379/210001 [00:47<00:13, 3660.84files/s]\u001b[A\n",
      " 76%|███████▌  | 159747/210001 [00:47<00:13, 3664.64files/s]\u001b[A\n",
      " 76%|███████▌  | 160121/210001 [00:47<00:13, 3681.40files/s]\u001b[A\n",
      " 76%|███████▋  | 160490/210001 [00:47<00:13, 3673.94files/s]\u001b[A\n",
      " 77%|███████▋  | 160888/210001 [00:48<00:13, 3760.36files/s]\u001b[A\n",
      " 77%|███████▋  | 161265/210001 [00:48<00:13, 3727.34files/s]\u001b[A\n",
      " 77%|███████▋  | 161643/210001 [00:48<00:12, 3741.57files/s]\u001b[A\n",
      " 77%|███████▋  | 162045/210001 [00:48<00:12, 3820.21files/s]\u001b[A\n",
      " 77%|███████▋  | 162428/210001 [00:48<00:12, 3758.41files/s]\u001b[A\n",
      " 78%|███████▊  | 162813/210001 [00:48<00:12, 3783.10files/s]\u001b[A\n",
      " 78%|███████▊  | 163192/210001 [00:48<00:12, 3764.67files/s]\u001b[A\n",
      " 78%|███████▊  | 163575/210001 [00:48<00:12, 3778.17files/s]\u001b[A\n",
      " 78%|███████▊  | 163956/210001 [00:48<00:12, 3784.81files/s]\u001b[A\n",
      " 78%|███████▊  | 164342/210001 [00:48<00:12, 3803.06files/s]\u001b[A\n",
      " 78%|███████▊  | 164733/210001 [00:49<00:11, 3831.67files/s]\u001b[A\n",
      " 79%|███████▊  | 165117/210001 [00:49<00:11, 3801.61files/s]\u001b[A\n",
      " 79%|███████▉  | 165498/210001 [00:49<00:11, 3759.11files/s]\u001b[A\n",
      " 79%|███████▉  | 165881/210001 [00:49<00:11, 3779.79files/s]\u001b[A\n",
      " 79%|███████▉  | 166274/210001 [00:49<00:11, 3823.22files/s]\u001b[A\n",
      " 79%|███████▉  | 166657/210001 [00:49<00:11, 3755.29files/s]\u001b[A\n",
      " 80%|███████▉  | 167033/210001 [00:49<00:11, 3731.04files/s]\u001b[A\n",
      " 80%|███████▉  | 167414/210001 [00:49<00:11, 3752.80files/s]\u001b[A\n",
      " 80%|███████▉  | 167805/210001 [00:49<00:11, 3790.08files/s]\u001b[A\n",
      " 80%|████████  | 168185/210001 [00:50<00:11, 3696.40files/s]\u001b[A\n",
      " 80%|████████  | 168569/210001 [00:50<00:11, 3735.21files/s]\u001b[A\n",
      " 80%|████████  | 168956/210001 [00:50<00:10, 3767.96files/s]\u001b[A\n",
      " 81%|████████  | 169334/210001 [00:50<00:10, 3706.95files/s]\u001b[A\n",
      " 81%|████████  | 169717/210001 [00:50<00:10, 3740.53files/s]\u001b[A\n",
      " 81%|████████  | 170114/210001 [00:50<00:10, 3802.21files/s]\u001b[A\n",
      " 81%|████████  | 170495/210001 [00:50<00:10, 3664.51files/s]\u001b[A\n",
      " 81%|████████▏ | 170863/210001 [00:50<00:11, 3545.69files/s]\u001b[A\n",
      " 82%|████████▏ | 171220/210001 [00:50<00:11, 3424.96files/s]\u001b[A\n",
      " 82%|████████▏ | 171565/210001 [00:50<00:11, 3338.18files/s]\u001b[A\n",
      " 82%|████████▏ | 171901/210001 [00:51<00:11, 3278.29files/s]\u001b[A\n",
      " 82%|████████▏ | 172231/210001 [00:51<00:11, 3212.84files/s]\u001b[A\n",
      " 82%|████████▏ | 172605/210001 [00:51<00:11, 3354.54files/s]\u001b[A\n",
      " 82%|████████▏ | 172990/210001 [00:51<00:10, 3480.31files/s]\u001b[A\n",
      " 83%|████████▎ | 173374/210001 [00:51<00:10, 3579.28files/s]\u001b[A\n",
      " 83%|████████▎ | 173735/210001 [00:51<00:10, 3488.73files/s]\u001b[A\n",
      " 83%|████████▎ | 174130/210001 [00:51<00:09, 3615.05files/s]\u001b[A\n",
      " 83%|████████▎ | 174522/210001 [00:51<00:09, 3699.54files/s]\u001b[A\n",
      " 83%|████████▎ | 174919/210001 [00:51<00:09, 3774.19files/s]\u001b[A\n",
      " 83%|████████▎ | 175315/210001 [00:52<00:09, 3826.43files/s]\u001b[A\n",
      " 84%|████████▎ | 175701/210001 [00:52<00:08, 3833.91files/s]\u001b[A\n",
      " 84%|████████▍ | 176086/210001 [00:52<00:09, 3663.38files/s]\u001b[A\n",
      " 84%|████████▍ | 176474/210001 [00:52<00:09, 3723.78files/s]\u001b[A\n",
      " 84%|████████▍ | 176880/210001 [00:52<00:08, 3815.50files/s]\u001b[A\n",
      " 84%|████████▍ | 177269/210001 [00:52<00:08, 3836.04files/s]\u001b[A\n",
      " 85%|████████▍ | 177654/210001 [00:52<00:08, 3830.78files/s]\u001b[A\n",
      " 85%|████████▍ | 178058/210001 [00:52<00:08, 3888.53files/s]\u001b[A\n",
      " 85%|████████▍ | 178448/210001 [00:52<00:08, 3671.35files/s]\u001b[A\n",
      " 85%|████████▌ | 178826/210001 [00:52<00:08, 3701.01files/s]\u001b[A\n",
      " 85%|████████▌ | 179229/210001 [00:53<00:08, 3791.58files/s]\u001b[A\n",
      " 86%|████████▌ | 179611/210001 [00:53<00:08, 3710.14files/s]\u001b[A\n",
      " 86%|████████▌ | 180005/210001 [00:53<00:07, 3774.09files/s]\u001b[A\n",
      " 86%|████████▌ | 180400/210001 [00:53<00:07, 3818.04files/s]\u001b[A\n",
      " 86%|████████▌ | 180797/210001 [00:53<00:07, 3861.48files/s]\u001b[A\n",
      " 86%|████████▋ | 181185/210001 [00:53<00:07, 3642.62files/s]\u001b[A\n",
      " 86%|████████▋ | 181553/210001 [00:53<00:07, 3609.42files/s]\u001b[A\n",
      " 87%|████████▋ | 181949/210001 [00:53<00:07, 3706.26files/s]\u001b[A\n",
      " 87%|████████▋ | 182322/210001 [00:53<00:07, 3700.92files/s]\u001b[A\n",
      " 87%|████████▋ | 182694/210001 [00:53<00:07, 3632.88files/s]\u001b[A\n",
      " 87%|████████▋ | 183059/210001 [00:54<00:07, 3602.99files/s]\u001b[A\n",
      " 87%|████████▋ | 183421/210001 [00:54<00:07, 3572.09files/s]\u001b[A\n",
      " 88%|████████▊ | 183779/210001 [00:54<00:07, 3538.62files/s]\u001b[A\n",
      " 88%|████████▊ | 184134/210001 [00:54<00:07, 3519.51files/s]\u001b[A\n",
      " 88%|████████▊ | 184509/210001 [00:54<00:07, 3585.50files/s]\u001b[A\n",
      " 88%|████████▊ | 184869/210001 [00:54<00:07, 3335.82files/s]\u001b[A\n",
      " 88%|████████▊ | 185207/210001 [00:54<00:07, 3225.47files/s]\u001b[A\n",
      " 88%|████████▊ | 185534/210001 [00:54<00:07, 3154.85files/s]\u001b[A\n",
      " 89%|████████▊ | 185885/210001 [00:54<00:07, 3252.95files/s]\u001b[A\n",
      " 89%|████████▊ | 186221/210001 [00:55<00:07, 3280.76files/s]\u001b[A\n",
      " 89%|████████▉ | 186571/210001 [00:55<00:07, 3342.50files/s]\u001b[A\n",
      " 89%|████████▉ | 186918/210001 [00:55<00:06, 3378.83files/s]\u001b[A\n",
      " 89%|████████▉ | 187302/210001 [00:55<00:06, 3503.44files/s]\u001b[A\n",
      " 89%|████████▉ | 187655/210001 [00:55<00:06, 3369.26files/s]\u001b[A\n",
      " 90%|████████▉ | 188029/210001 [00:55<00:06, 3471.21files/s]\u001b[A\n",
      " 90%|████████▉ | 188421/210001 [00:55<00:06, 3592.95files/s]\u001b[A\n",
      " 90%|████████▉ | 188802/210001 [00:55<00:05, 3653.52files/s]\u001b[A\n",
      " 90%|█████████ | 189170/210001 [00:55<00:06, 3413.79files/s]\u001b[A\n",
      " 90%|█████████ | 189517/210001 [00:55<00:06, 3320.19files/s]\u001b[A\n",
      " 90%|█████████ | 189853/210001 [00:56<00:06, 3268.87files/s]\u001b[A\n",
      " 91%|█████████ | 190239/210001 [00:56<00:05, 3424.30files/s]\u001b[A\n",
      " 91%|█████████ | 190623/210001 [00:56<00:05, 3537.87files/s]\u001b[A\n",
      " 91%|█████████ | 190981/210001 [00:56<00:05, 3542.72files/s]\u001b[A\n",
      " 91%|█████████ | 191367/210001 [00:56<00:05, 3629.54files/s]\u001b[A\n",
      " 91%|█████████▏| 191744/210001 [00:56<00:04, 3667.83files/s]\u001b[A\n",
      " 91%|█████████▏| 192144/210001 [00:56<00:04, 3759.51files/s]\u001b[A\n",
      " 92%|█████████▏| 192540/210001 [00:56<00:04, 3816.85files/s]\u001b[A\n",
      " 92%|█████████▏| 192932/210001 [00:56<00:04, 3847.01files/s]\u001b[A\n",
      " 92%|█████████▏| 193325/210001 [00:57<00:04, 3870.54files/s]\u001b[A\n",
      " 92%|█████████▏| 193725/210001 [00:57<00:04, 3907.34files/s]\u001b[A\n",
      " 92%|█████████▏| 194117/210001 [00:57<00:04, 3772.51files/s]\u001b[A\n",
      " 93%|█████████▎| 194510/210001 [00:57<00:04, 3817.12files/s]\u001b[A\n",
      " 93%|█████████▎| 194895/210001 [00:57<00:03, 3825.12files/s]\u001b[A\n",
      " 93%|█████████▎| 195280/210001 [00:57<00:03, 3831.10files/s]\u001b[A\n",
      " 93%|█████████▎| 195664/210001 [00:57<00:03, 3789.01files/s]\u001b[A\n",
      " 93%|█████████▎| 196044/210001 [00:57<00:03, 3785.72files/s]\u001b[A\n",
      " 94%|█████████▎| 196423/210001 [00:57<00:03, 3744.81files/s]\u001b[A\n",
      " 94%|█████████▎| 196812/210001 [00:57<00:03, 3786.95files/s]\u001b[A\n",
      " 94%|█████████▍| 197201/210001 [00:58<00:03, 3814.93files/s]\u001b[A\n",
      " 94%|█████████▍| 197583/210001 [00:58<00:03, 3806.40files/s]\u001b[A\n",
      " 94%|█████████▍| 197974/210001 [00:58<00:03, 3836.26files/s]\u001b[A\n",
      " 94%|█████████▍| 198358/210001 [00:58<00:03, 3797.17files/s]\u001b[A\n",
      " 95%|█████████▍| 198738/210001 [00:58<00:02, 3793.87files/s]\u001b[A\n",
      " 95%|█████████▍| 199134/210001 [00:58<00:02, 3834.93files/s]\u001b[A\n",
      " 95%|█████████▌| 199518/210001 [00:58<00:02, 3826.79files/s]\u001b[A\n",
      " 95%|█████████▌| 199911/210001 [00:58<00:02, 3853.40files/s]\u001b[A\n",
      " 95%|█████████▌| 200305/210001 [00:58<00:02, 3877.25files/s]\u001b[A\n",
      " 96%|█████████▌| 200693/210001 [00:58<00:02, 3647.13files/s]\u001b[A\n",
      " 96%|█████████▌| 201061/210001 [00:59<00:02, 3169.21files/s]\u001b[A\n",
      " 96%|█████████▌| 201392/210001 [00:59<00:02, 3027.70files/s]\u001b[A\n",
      " 96%|█████████▌| 201706/210001 [00:59<00:02, 3037.23files/s]\u001b[A\n",
      " 96%|█████████▌| 202018/210001 [00:59<00:02, 2855.26files/s]\u001b[A\n",
      " 96%|█████████▋| 202311/210001 [00:59<00:02, 2848.76files/s]\u001b[A\n",
      " 97%|█████████▋| 202651/210001 [00:59<00:02, 2994.17files/s]\u001b[A\n",
      " 97%|█████████▋| 203031/210001 [00:59<00:02, 3193.66files/s]\u001b[A\n",
      " 97%|█████████▋| 203416/210001 [00:59<00:01, 3363.37files/s]\u001b[A\n",
      " 97%|█████████▋| 203761/210001 [00:59<00:01, 3305.80files/s]\u001b[A\n",
      " 97%|█████████▋| 204098/210001 [01:00<00:01, 3303.94files/s]\u001b[A\n",
      " 97%|█████████▋| 204483/210001 [01:00<00:01, 3450.00files/s]\u001b[A\n",
      " 98%|█████████▊| 204833/210001 [01:00<00:01, 3371.62files/s]\u001b[A\n",
      " 98%|█████████▊| 205218/210001 [01:00<00:01, 3501.86files/s]\u001b[A\n",
      " 98%|█████████▊| 205599/210001 [01:00<00:01, 3588.41files/s]\u001b[A\n",
      " 98%|█████████▊| 205961/210001 [01:00<00:01, 3561.45files/s]\u001b[A\n",
      " 98%|█████████▊| 206356/210001 [01:00<00:00, 3668.03files/s]\u001b[A\n",
      " 98%|█████████▊| 206726/210001 [01:00<00:00, 3490.66files/s]\u001b[A\n",
      " 99%|█████████▊| 207079/210001 [01:00<00:00, 3418.70files/s]\u001b[A\n",
      " 99%|█████████▉| 207424/210001 [01:01<00:00, 3269.96files/s]\u001b[A\n",
      " 99%|█████████▉| 207755/210001 [01:01<00:00, 3128.62files/s]\u001b[A\n",
      " 99%|█████████▉| 208072/210001 [01:01<00:00, 2886.06files/s]\u001b[A\n",
      " 99%|█████████▉| 208367/210001 [01:01<00:00, 2670.63files/s]\u001b[A\n",
      " 99%|█████████▉| 208642/210001 [01:01<00:00, 2682.05files/s]\u001b[A\n",
      " 99%|█████████▉| 208916/210001 [01:01<00:00, 2574.41files/s]\u001b[A\n",
      "100%|█████████▉| 209179/210001 [01:01<00:00, 2431.11files/s]\u001b[A\n",
      "100%|█████████▉| 209541/210001 [01:01<00:00, 2696.12files/s]\u001b[A\n",
      "100%|█████████▉| 209868/210001 [01:01<00:00, 2844.51files/s]\u001b[A\n",
      "100%|██████████| 210001/210001 [01:01<00:00, 3387.62files/s]\u001b[A\n",
      "  0%|          | 0/10001 [00:00<?, ?files/s]\u001b[A\n",
      "  0%|          | 2/10001 [00:00<39:35,  4.21files/s]\u001b[A\n",
      "  3%|▎         | 335/10001 [00:00<26:48,  6.01files/s]\u001b[A\n",
      "  7%|▋         | 660/10001 [00:00<18:09,  8.58files/s]\u001b[A\n",
      "  8%|▊         | 828/10001 [00:00<12:30, 12.22files/s]\u001b[A\n",
      " 12%|█▏        | 1210/10001 [00:00<08:24, 17.43files/s]\u001b[A\n",
      " 14%|█▍        | 1436/10001 [00:01<05:45, 24.76files/s]\u001b[A\n",
      " 18%|█▊        | 1812/10001 [00:01<03:52, 35.27files/s]\u001b[A\n",
      " 22%|██▏       | 2205/10001 [00:01<02:35, 50.19files/s]\u001b[A\n",
      " 26%|██▌       | 2602/10001 [00:01<01:43, 71.31files/s]\u001b[A\n",
      " 30%|██▉       | 2995/10001 [00:01<01:09, 101.08files/s]\u001b[A\n",
      " 34%|███▍      | 3404/10001 [00:01<00:46, 142.89files/s]\u001b[A\n",
      " 38%|███▊      | 3812/10001 [00:01<00:30, 201.10files/s]\u001b[A\n",
      " 42%|████▏     | 4216/10001 [00:01<00:20, 281.27files/s]\u001b[A\n",
      " 46%|████▌     | 4609/10001 [00:01<00:13, 389.85files/s]\u001b[A\n",
      " 50%|█████     | 5002/10001 [00:01<00:09, 534.20files/s]\u001b[A\n",
      " 54%|█████▍    | 5402/10001 [00:02<00:06, 721.82files/s]\u001b[A\n",
      " 58%|█████▊    | 5805/10001 [00:02<00:04, 957.39files/s]\u001b[A\n",
      " 62%|██████▏   | 6203/10001 [00:02<00:03, 1239.40files/s]\u001b[A\n",
      " 66%|██████▌   | 6599/10001 [00:02<00:02, 1556.14files/s]\u001b[A\n",
      " 70%|███████   | 7001/10001 [00:02<00:01, 1906.67files/s]\u001b[A\n",
      " 74%|███████▍  | 7415/10001 [00:02<00:01, 2274.59files/s]\u001b[A\n",
      " 78%|███████▊  | 7819/10001 [00:02<00:00, 2615.09files/s]\u001b[A\n",
      " 82%|████████▏ | 8231/10001 [00:02<00:00, 2935.87files/s]\u001b[A\n",
      " 86%|████████▋ | 8645/10001 [00:02<00:00, 3214.77files/s]\u001b[A\n",
      " 91%|█████████ | 9052/10001 [00:02<00:00, 3417.44files/s]\u001b[A\n",
      " 95%|█████████▍| 9457/10001 [00:03<00:00, 3581.54files/s]\u001b[A\n",
      " 99%|█████████▊| 9862/10001 [00:03<00:00, 3663.91files/s]\u001b[A\n",
      "100%|██████████| 10001/10001 [00:03<00:00, 3095.98files/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features and labels uncompressed.\n"
     ]
    }
   ],
   "source": [
    "def uncompress_features_labels(file):\n",
    "    \"\"\"\n",
    "    Uncompress features and labels from a zip file\n",
    "    :param file: The zip file to extract the data from\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with ZipFile(file) as zipf:\n",
    "        # Progress Bar\n",
    "        filenames_pbar = tqdm(zipf.namelist(), unit='files')\n",
    "        \n",
    "        # Get features and labels from all files\n",
    "        for filename in filenames_pbar:\n",
    "            # Check if the file is a directory\n",
    "            if not filename.endswith('/'):\n",
    "                with zipf.open(filename) as image_file:\n",
    "                    image = Image.open(image_file)\n",
    "                    image.load()\n",
    "                    # Load image data as 1 dimensional array\n",
    "                    # We're using float32 to save on memory space\n",
    "                    feature = np.array(image, dtype=np.float32).flatten()\n",
    "\n",
    "                # Get the the letter from the filename.  This is the letter of the image.\n",
    "                label = os.path.split(filename)[1][0]\n",
    "\n",
    "                features.append(feature)\n",
    "                labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Get the features and labels from the zip files\n",
    "train_features, train_labels = uncompress_features_labels('notMNIST_train.zip')\n",
    "test_features, test_labels = uncompress_features_labels('notMNIST_test.zip')\n",
    "\n",
    "# Limit the amount of data to work with a docker container\n",
    "docker_size_limit = 150000\n",
    "train_features, train_labels = resample(train_features, train_labels, n_samples=docker_size_limit)\n",
    "\n",
    "# Set flags for feature engineering.  This will prevent you from skipping an important step.\n",
    "is_features_normal = False\n",
    "is_labels_encod = False\n",
    "\n",
    "# Wait until you see that all features and labels have been uncompressed.\n",
    "print('All features and labels uncompressed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/mean_variance.png\" style=\"height: 75%;width: 75%; position: relative; right: 5%\">\n",
    "## Problem 1\n",
    "The first problem involves normalizing the features for your training and test data.\n",
    "\n",
    "Implement Min-Max scaling in the `normalize()` function to a range of `a=0.1` and `b=0.9`. After scaling, the values of the pixels in the input data should range from 0.1 to 0.9.\n",
    "\n",
    "Since the raw notMNIST image data is in [grayscale](https://en.wikipedia.org/wiki/Grayscale), the current values range from a min of 0 to a max of 255.\n",
    "\n",
    "Min-Max Scaling:\n",
    "$\n",
    "X'=a+{\\frac {\\left(X-X_{\\min }\\right)\\left(b-a\\right)}{X_{\\max }-X_{\\min }}}\n",
    "$\n",
    "\n",
    "*If you're having trouble solving problem 1, you can view the solution [here](https://github.com/udacity/CarND-TensorFlow-Lab/blob/master/solutions.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "# Problem 1 - Implement Min-Max scaling for grayscale image data\n",
    "def normalize_grayscale(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Min-Max scaling for grayscale image data\n",
    "    a=0.1\n",
    "    b=0.9\n",
    "    X_min=0\n",
    "    X_max=255\n",
    "    return a + (image_data - X_min)*(b-a)/(X_max-X_min)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# Test Cases\n",
    "np.testing.assert_array_almost_equal(\n",
    "    normalize_grayscale(np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 255])),\n",
    "    [0.1, 0.103137254902, 0.106274509804, 0.109411764706, 0.112549019608, 0.11568627451, 0.118823529412, 0.121960784314,\n",
    "     0.125098039216, 0.128235294118, 0.13137254902, 0.9],\n",
    "    decimal=3)\n",
    "np.testing.assert_array_almost_equal(\n",
    "    normalize_grayscale(np.array([0, 1, 10, 20, 30, 40, 233, 244, 254,255])),\n",
    "    [0.1, 0.103137254902, 0.13137254902, 0.162745098039, 0.194117647059, 0.225490196078, 0.830980392157, 0.865490196078,\n",
    "     0.896862745098, 0.9])\n",
    "\n",
    "if not is_features_normal:\n",
    "    train_features = normalize_grayscale(train_features)\n",
    "    test_features = normalize_grayscale(test_features)\n",
    "    is_features_normal = True\n",
    "\n",
    "print('Tests Passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels One-Hot Encoded\n"
     ]
    }
   ],
   "source": [
    "if not is_labels_encod:\n",
    "    # Turn labels into numbers and apply One-Hot Encoding\n",
    "    encoder = LabelBinarizer()\n",
    "    encoder.fit(train_labels)\n",
    "    train_labels = encoder.transform(train_labels)\n",
    "    test_labels = encoder.transform(test_labels)\n",
    "\n",
    "    # Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "    train_labels = train_labels.astype(np.float32)\n",
    "    test_labels = test_labels.astype(np.float32)\n",
    "    is_labels_encod = True\n",
    "\n",
    "print('Labels One-Hot Encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features and labels randomized and split.\n"
     ]
    }
   ],
   "source": [
    "assert is_features_normal, 'You skipped the step to normalize the features'\n",
    "assert is_labels_encod, 'You skipped the step to One-Hot Encode the labels'\n",
    "\n",
    "# Get randomized datasets for training and validation\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    test_size=0.05,\n",
    "    random_state=832289)\n",
    "\n",
    "print('Training features and labels randomized and split.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cached in pickle file.\n"
     ]
    }
   ],
   "source": [
    "# Save the data for easy access\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "if not os.path.isfile(pickle_file):\n",
    "    print('Saving data to pickle file...')\n",
    "    try:\n",
    "        with open('notMNIST.pickle', 'wb') as pfile:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    'train_dataset': train_features,\n",
    "                    'train_labels': train_labels,\n",
    "                    'valid_dataset': valid_features,\n",
    "                    'valid_labels': valid_labels,\n",
    "                    'test_dataset': test_features,\n",
    "                    'test_labels': test_labels,\n",
    "                },\n",
    "                pfile, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', pickle_file, ':', e)\n",
    "        raise\n",
    "\n",
    "print('Data cached in pickle file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "All your progress is now saved to the pickle file.  If you need to leave and comeback to this lab, you no longer have to start from the beginning.  Just run the code block below and it will load all the data and modules required to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and modules loaded.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load the modules\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reload the data\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  pickle_data = pickle.load(f)\n",
    "  train_features = pickle_data['train_dataset']\n",
    "  train_labels = pickle_data['train_labels']\n",
    "  valid_features = pickle_data['valid_dataset']\n",
    "  valid_labels = pickle_data['valid_labels']\n",
    "  test_features = pickle_data['test_dataset']\n",
    "  test_labels = pickle_data['test_labels']\n",
    "  del pickle_data  # Free up memory\n",
    "\n",
    "\n",
    "print('Data and modules loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/weight_biases.png\" style=\"height: 60%;width: 60%; position: relative; right: 10%\">\n",
    "## Problem 2\n",
    "For the neural network to train on your data, you need the following <a href=\"https://www.tensorflow.org/resources/dims_types.html#data-types\">float32</a> tensors:\n",
    " - `features`\n",
    "  - Placeholder tensor for feature data (`train_features`/`valid_features`/`test_features`)\n",
    " - `labels`\n",
    "  - Placeholder tensor for label data (`train_labels`/`valid_labels`/`test_labels`)\n",
    " - `weights`\n",
    "  - Variable Tensor with random numbers from a truncated normal distribution.\n",
    "    - See <a href=\"https://www.tensorflow.org/api_docs/python/constant_op.html#truncated_normal\">`tf.truncated_normal()` documentation</a> for help.\n",
    " - `biases`\n",
    "  - Variable Tensor with all zeros.\n",
    "    - See <a href=\"https://www.tensorflow.org/api_docs/python/constant_op.html#zeros\"> `tf.zeros()` documentation</a> for help.\n",
    "\n",
    "*If you're having trouble solving problem 2, review \"TensorFlow Linear Function\" section of the class.  If that doesn't help, the solution for this problem is available [here](https://github.com/udacity/CarND-TensorFlow-Lab/blob/master/solutions.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "features_count = 784\n",
    "labels_count = 10\n",
    "\n",
    "# TODO: Set the features and labels tensors\n",
    "features = tf.placeholder(tf.float32,[None,features_count])\n",
    "labels = tf.placeholder(tf.float32,[None,labels_count])\n",
    "\n",
    "# TODO: Set the weights and biases tensors\n",
    "weights = tf.Variable(tf.random_normal([features_count,labels_count]))\n",
    "biases = tf.Variable(tf.zeros(labels_count))\n",
    "\n",
    "\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "\n",
    "#Test Cases\n",
    "from tensorflow.python.ops.variables import Variable\n",
    "\n",
    "assert features._op.name.startswith('Placeholder'), 'features must be a placeholder'\n",
    "assert labels._op.name.startswith('Placeholder'), 'labels must be a placeholder'\n",
    "assert isinstance(weights, Variable), 'weights must be a TensorFlow variable'\n",
    "assert isinstance(biases, Variable), 'biases must be a TensorFlow variable'\n",
    "\n",
    "assert features._shape == None or (\\\n",
    "    features._shape.dims[0].value is None and\\\n",
    "    features._shape.dims[1].value in [None, 784]), 'The shape of features is incorrect'\n",
    "assert labels._shape  == None or (\\\n",
    "    labels._shape.dims[0].value is None and\\\n",
    "    labels._shape.dims[1].value in [None, 10]), 'The shape of labels is incorrect'\n",
    "assert weights._variable._shape == (784, 10), 'The shape of weights is incorrect'\n",
    "assert biases._variable._shape == (10), 'The shape of biases is incorrect'\n",
    "\n",
    "assert features._dtype == tf.float32, 'features must be type float32'\n",
    "assert labels._dtype == tf.float32, 'labels must be type float32'\n",
    "\n",
    "# Feed dicts for training, validation, and test session\n",
    "train_feed_dict = {features: train_features, labels: train_labels}\n",
    "valid_feed_dict = {features: valid_features, labels: valid_labels}\n",
    "test_feed_dict = {features: test_features, labels: test_labels}\n",
    "\n",
    "# Linear Function WX + b\n",
    "logits = tf.matmul(features, weights) + biases\n",
    "\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Cross entropy\n",
    "cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
    "\n",
    "# Training loss\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Create an operation that initializes all variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Test Cases\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    session.run(loss, feed_dict=train_feed_dict)\n",
    "    session.run(loss, feed_dict=valid_feed_dict)\n",
    "    session.run(loss, feed_dict=test_feed_dict)\n",
    "    biases_data = session.run(biases)\n",
    "\n",
    "assert not np.count_nonzero(biases_data), 'biases must be zeros'\n",
    "\n",
    "print('Tests Passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy function created.\n"
     ]
    }
   ],
   "source": [
    "# Determine if the predictions are correct\n",
    "is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32))\n",
    "\n",
    "print('Accuracy function created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/learn_rate_tune.png\" style=\"height: 60%;width: 60%\">\n",
    "## Problem 3\n",
    "Below are 3 parameter configurations for training the neural network. In each configuration, one of the parameters has multiple options. For each configuration, choose the option that gives the best acccuracy.\n",
    "\n",
    "Parameter configurations:\n",
    "\n",
    "Configuration 1\n",
    "* **Epochs:** 1\n",
    "* **Batch Size:**\n",
    "  * 2000\n",
    "  * 1000\n",
    "  * 500\n",
    "  * 300\n",
    "  * 50\n",
    "* **Learning Rate:** 0.01\n",
    "\n",
    "Configuration 2\n",
    "* **Epochs:** 1\n",
    "* **Batch Size:** 100\n",
    "* **Learning Rate:**\n",
    "  * 0.8\n",
    "  * 0.5\n",
    "  * 0.1\n",
    "  * 0.05\n",
    "  * 0.01\n",
    "\n",
    "Configuration 3\n",
    "* **Epochs:**\n",
    "  * 1\n",
    "  * 2\n",
    "  * 3\n",
    "  * 4\n",
    "  * 5\n",
    "* **Batch Size:** 100\n",
    "* **Learning Rate:** 0.2\n",
    "\n",
    "The code will print out a Loss and Accuracy graph, so you can see how well the neural network performed.\n",
    "\n",
    "*If you're having trouble solving problem 3, you can view the solution [here](https://github.com/udacity/CarND-TensorFlow-Lab/blob/master/solutions.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/1:   0%|          | 0/475 [00:00<?, ?batches/s]\u001b[A\n",
      "Epoch  1/1:   0%|          | 1/475 [00:00<06:48,  1.16batches/s]\u001b[A\n",
      "Epoch  1/1:   5%|▍         | 22/475 [00:00<04:34,  1.65batches/s]\u001b[A\n",
      "Epoch  1/1:   9%|▉         | 43/475 [00:01<03:03,  2.35batches/s]\u001b[A\n",
      "Epoch  1/1:  11%|█▏        | 54/475 [00:01<02:11,  3.21batches/s]\u001b[A\n",
      "Epoch  1/1:  16%|█▌        | 75/475 [00:01<01:27,  4.55batches/s]\u001b[A\n",
      "Epoch  1/1:  20%|██        | 97/475 [00:01<00:58,  6.44batches/s]\u001b[A\n",
      "Epoch  1/1:  24%|██▎       | 112/475 [00:02<00:43,  8.34batches/s]\u001b[A\n",
      "Epoch  1/1:  28%|██▊       | 133/475 [00:02<00:29, 11.72batches/s]\u001b[A\n",
      "Epoch  1/1:  32%|███▏      | 151/475 [00:03<00:22, 14.49batches/s]\u001b[A\n",
      "Epoch  1/1:  36%|███▌      | 170/475 [00:03<00:15, 20.04batches/s]\u001b[A\n",
      "Epoch  1/1:  39%|███▊      | 184/475 [00:03<00:11, 26.29batches/s]\u001b[A\n",
      "Epoch  1/1:  42%|████▏     | 201/475 [00:03<00:09, 27.72batches/s]\u001b[A\n",
      "Epoch  1/1:  47%|████▋     | 222/475 [00:03<00:06, 37.43batches/s]\u001b[A\n",
      "Epoch  1/1:  51%|█████▏    | 244/475 [00:03<00:04, 49.80batches/s]\u001b[A\n",
      "Epoch  1/1:  55%|█████▍    | 260/475 [00:04<00:05, 41.39batches/s]\u001b[A\n",
      "Epoch  1/1:  59%|█████▉    | 282/475 [00:04<00:03, 54.68batches/s]\u001b[A\n",
      "Epoch  1/1:  63%|██████▎   | 301/475 [00:05<00:03, 46.75batches/s]\u001b[A\n",
      "Epoch  1/1:  68%|██████▊   | 323/475 [00:05<00:02, 61.18batches/s]\u001b[A\n",
      "Epoch  1/1:  73%|███████▎  | 347/475 [00:05<00:01, 78.46batches/s]\u001b[A\n",
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sujay/anaconda2/envs/python3/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/sujay/anaconda2/envs/python3/lib/python3.5/site-packages/tqdm/_tqdm.py\", line 102, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/sujay/anaconda2/envs/python3/lib/python3.5/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "Epoch  1/1: 100%|██████████| 475/475 [00:07<00:00, 63.45batches/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAGGCAYAAABmPbWyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb0684d97b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy at 0.10520000010728836\n"
     ]
    }
   ],
   "source": [
    "# TODO: Find the best parameters for each configuration\n",
    "epochs = 1\n",
    "batch_size = 300\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)    \n",
    "\n",
    "# The accuracy measured against the validation set\n",
    "validation_accuracy = 0.0\n",
    "\n",
    "# Measurements use for graphing loss and accuracy\n",
    "log_batch_step = 50\n",
    "batches = []\n",
    "loss_batch = []\n",
    "train_acc_batch = []\n",
    "valid_acc_batch = []\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer and get loss\n",
    "            _, l = session.run(\n",
    "                [optimizer, loss],\n",
    "                feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "            # Log every 50 batches\n",
    "            if not batch_i % log_batch_step:\n",
    "                # Calculate Training and Validation accuracy\n",
    "                training_accuracy = session.run(accuracy, feed_dict=train_feed_dict)\n",
    "                validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "\n",
    "                # Log batches\n",
    "                previous_batch = batches[-1] if batches else 0\n",
    "                batches.append(log_batch_step + previous_batch)\n",
    "                loss_batch.append(l)\n",
    "                train_acc_batch.append(training_accuracy)\n",
    "                valid_acc_batch.append(validation_accuracy)\n",
    "\n",
    "        # Check accuracy against Validation data\n",
    "        validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "\n",
    "loss_plot = plt.subplot(211)\n",
    "loss_plot.set_title('Loss')\n",
    "loss_plot.plot(batches, loss_batch, 'g')\n",
    "loss_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot = plt.subplot(212)\n",
    "acc_plot.set_title('Accuracy')\n",
    "acc_plot.plot(batches, train_acc_batch, 'r', label='Training Accuracy')\n",
    "acc_plot.plot(batches, valid_acc_batch, 'x', label='Validation Accuracy')\n",
    "acc_plot.set_ylim([0, 1.0])\n",
    "acc_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot.legend(loc=4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Validation accuracy at {}'.format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "Set the epochs, batch_size, and learning_rate with the best learning parameters you discovered in problem 3.  You're going to test your model against your hold out dataset/testing data.  This will give you a good indicator of how well the model will do in the real world.  You should have a test accuracy of at least 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1/10: 100%|██████████| 1425/1425 [00:03<00:00, 416.78batches/s]\n",
      "Epoch  2/10: 100%|██████████| 1425/1425 [00:03<00:00, 456.41batches/s]\n",
      "Epoch  3/10: 100%|██████████| 1425/1425 [00:03<00:00, 405.85batches/s]\n",
      "Epoch  4/10: 100%|██████████| 1425/1425 [00:03<00:00, 413.34batches/s]\n",
      "Epoch  5/10: 100%|██████████| 1425/1425 [00:03<00:00, 467.99batches/s]\n",
      "Epoch  6/10: 100%|██████████| 1425/1425 [00:03<00:00, 415.21batches/s]\n",
      "Epoch  7/10: 100%|██████████| 1425/1425 [00:03<00:00, 416.21batches/s]\n",
      "Epoch  8/10: 100%|██████████| 1425/1425 [00:03<00:00, 411.83batches/s]\n",
      "Epoch  9/10: 100%|██████████| 1425/1425 [00:03<00:00, 410.16batches/s]\n",
      "Epoch 10/10: 100%|██████████| 1425/1425 [00:03<00:00, 409.83batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice Job! Test Accuracy is 0.8113999962806702\n"
     ]
    }
   ],
   "source": [
    "# TODO: Set the epochs, batch_size, and learning_rate with the best parameters from problem 3\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# The accuracy measured against the test set\n",
    "test_accuracy = 0.0\n",
    "\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer\n",
    "            _ = session.run(optimizer, feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "        # Check accuracy against Test data\n",
    "        test_accuracy = session.run(accuracy, feed_dict=test_feed_dict)\n",
    "\n",
    "\n",
    "assert test_accuracy >= 0.80, 'Test accuracy at {}, should be equal to or greater than 0.80'.format(test_accuracy)\n",
    "print('Nice Job! Test Accuracy is {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple layers\n",
    "Good job!  You built a one layer TensorFlow network!  However, you want to build more than one layer.  This is deep learning after all!  In the next section, you will start to satisfy your need for more layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
